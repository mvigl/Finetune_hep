{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasvigl/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from comet_ml import Experiment,ExistingExperiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "import yaml\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Finetune_hep.python import train,helpers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = helpers.get_device()\n",
    "data_config_Xbb = 'config/ParT_Xbb_config.yaml'\n",
    "data_config_latent = 'config/ParT_latent_config.yaml'\n",
    "data_config_latent_hlf = 'config/ParT_latent_hlf_config.yaml'\n",
    "data_config_Xbb_hlf = 'config/ParT_Xbb_hlf_config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_latent_hlf_head = models.head(data_config_Xbb_hlf,for_inference=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'phi.0.weight' in model_latent_hlf_head.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Xbb = models.full_model(data_config_Xbb,for_inference=True)  \n",
    "model_latent = models.full_model(data_config_latent,for_inference=False)  \n",
    "model_Xbb_hlf = models.full_model(data_config_Xbb_hlf,for_inference=True,save_representaions=True)  \n",
    "model_latent_hlf = models.full_model(data_config_latent_hlf,for_inference=True,save_representaions=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticleTransformerWrapper(\n",
       "  (head): InvariantModel(\n",
       "    (phi): Sequential(\n",
       "      (0): Linear(in_features=133, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (rho): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (mod): ParticleTransformer(\n",
       "    (trimmer): SequenceTrimmer()\n",
       "    (embed): Embed(\n",
       "      (input_bn): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (embed): Sequential(\n",
       "        (0): LayerNorm((17,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=17, out_features=128, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (7): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (8): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (pair_embed): PairEmbed(\n",
       "      (embed): Sequential(\n",
       "        (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): GELU(approximate='none')\n",
       "        (10): Conv1d(64, 8, kernel_size=(1,), stride=(1,))\n",
       "        (11): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (12): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (act_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (cls_blocks): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (act_dropout): Dropout(p=0, inplace=False)\n",
       "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_latent_hlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticleTransformerWrapper(\n",
       "  (Xbb): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (head): InvariantModel(\n",
       "    (phi): Sequential(\n",
       "      (0): Linear(in_features=6, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (rho): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (mod): ParticleTransformer(\n",
       "    (trimmer): SequenceTrimmer()\n",
       "    (embed): Embed(\n",
       "      (input_bn): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (embed): Sequential(\n",
       "        (0): LayerNorm((17,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=17, out_features=128, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (7): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (8): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (pair_embed): PairEmbed(\n",
       "      (embed): Sequential(\n",
       "        (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): GELU(approximate='none')\n",
       "        (10): Conv1d(64, 8, kernel_size=(1,), stride=(1,))\n",
       "        (11): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (12): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (act_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (cls_blocks): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (act_dropout): Dropout(p=0, inplace=False)\n",
       "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Xbb_hlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticleTransformerWrapper(\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (mod): ParticleTransformer(\n",
       "    (trimmer): SequenceTrimmer()\n",
       "    (embed): Embed(\n",
       "      (input_bn): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (embed): Sequential(\n",
       "        (0): LayerNorm((17,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=17, out_features=128, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (7): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (8): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (pair_embed): PairEmbed(\n",
       "      (embed): Sequential(\n",
       "        (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): GELU(approximate='none')\n",
       "        (10): Conv1d(64, 8, kernel_size=(1,), stride=(1,))\n",
       "        (11): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (12): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (act_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (cls_blocks): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (pre_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (post_attn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (pre_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (act_dropout): Dropout(p=0, inplace=False)\n",
       "        (post_fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xbb'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Xbb.Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['X_jet', 'X_jet_singlejet', 'X_label', 'X_label_singlejet', 'X_pfo', 'X_pfo_singlejet', 'jet_mask', 'labels']>\n",
      "<HDF5 dataset \"X_jet\": shape (26, 5, 6), type \"<f8\">\n",
      "<HDF5 dataset \"X_jet_singlejet\": shape (60, 6), type \"<f8\">\n",
      "<HDF5 dataset \"X_pfo_singlejet\": shape (60, 100, 15), type \"<f8\">\n",
      "<KeysViewHDF5 ['X_jet', 'X_jet_singlejet', 'X_label', 'X_label_singlejet', 'X_pfo', 'X_pfo_singlejet', 'jet_mask', 'labels']>\n",
      "<HDF5 dataset \"X_jet\": shape (3536, 5, 6), type \"<f8\">\n",
      "<HDF5 dataset \"X_jet_singlejet\": shape (7975, 6), type \"<f8\">\n",
      "<HDF5 dataset \"X_pfo_singlejet\": shape (7975, 100, 15), type \"<f8\">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiasvigl/Documents/Physics/EndToEnd/public/Finetune_hep/python/helpers.py:72: RuntimeWarning: divide by zero encountered in log\n",
      "  result = np.log(ma_data)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../data/Data_val_sig_30.h5', 'r') as sample_sig:\n",
    "    data = {}\n",
    "    print(sample_sig.keys())\n",
    "    print(sample_sig['X_jet'])\n",
    "    print(sample_sig['X_jet_singlejet'])\n",
    "    print(sample_sig['X_pfo_singlejet'])\n",
    "    data['X_jet'] = sample_sig['X_jet'][:]\n",
    "    data['X_pfo'] = sample_sig['X_pfo'][:]\n",
    "    data['labels'] = sample_sig['labels'][:]\n",
    "    data['jet_mask'] = sample_sig['jet_mask'][:]\n",
    "    inputs = helpers.build_features_and_labels(data)\n",
    "    data_Xbb = {}\n",
    "    data_Xbb['X_jet'] = sample_sig['X_jet_singlejet'][:]\n",
    "    data_Xbb['X_pfo'] = sample_sig['X_pfo_singlejet'][:]\n",
    "    data_Xbb['labels'] = sample_sig['X_label_singlejet'][:]\n",
    "    inputs_Xbb = helpers.build_features_and_labels_Xbb(data_Xbb)\n",
    "with h5py.File('../data/Data_val_bkg_100.h5', 'r') as sample_bkg:\n",
    "    data_bkg = {}\n",
    "    print(sample_bkg.keys())\n",
    "    print(sample_bkg['X_jet'])\n",
    "    print(sample_bkg['X_jet_singlejet'])\n",
    "    print(sample_bkg['X_pfo_singlejet'])\n",
    "    data_bkg['X_jet'] = sample_bkg['X_jet'][:100]\n",
    "    data_bkg['X_pfo'] = sample_bkg['X_pfo'][:100]\n",
    "    data_bkg['labels'] = sample_bkg['labels'][:100]\n",
    "    data_bkg['jet_mask'] = sample_bkg['jet_mask'][:100]\n",
    "    inputs_bkg = helpers.build_features_and_labels(data_bkg)\n",
    "    data_Xbb_bkg = {}\n",
    "    data_Xbb_bkg['X_jet'] = sample_bkg['X_jet_singlejet'][:100]\n",
    "    data_Xbb_bkg['X_pfo'] = sample_bkg['X_pfo_singlejet'][:100]\n",
    "    data_Xbb_bkg['labels'] = sample_bkg['X_label_singlejet'][:100]\n",
    "    inputs_Xbb_bkg = helpers.build_features_and_labels_Xbb(data_Xbb_bkg)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pf_points', 'pf_features', 'pf_vectors', 'pf_mask', 'jet_mask', 'label', 'hl_feats'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_points = torch.tensor(inputs['pf_points']).float().to(device)\n",
    "pf_features = torch.tensor(inputs['pf_features']).float().to(device)\n",
    "pf_vectors = torch.tensor(inputs['pf_vectors']).float().to(device)\n",
    "pf_mask = torch.tensor(inputs['pf_mask']).float().to(device)\n",
    "hl_feats = torch.tensor(inputs['hl_feats']).float().to(device)\n",
    "jet_mask = torch.tensor(inputs['jet_mask']).float().to(device)\n",
    "\n",
    "preds = model_latent(pf_points,pf_features,pf_vectors,pf_mask,jet_mask,hl_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_points = torch.tensor(inputs_Xbb['pf_points']).float().to(device)\n",
    "pf_features = torch.tensor(inputs_Xbb['pf_features']).float().to(device)\n",
    "pf_vectors = torch.tensor(inputs_Xbb['pf_vectors']).float().to(device)\n",
    "pf_mask = torch.tensor(inputs_Xbb['pf_mask']).float().to(device)\n",
    "\n",
    "pf_points_bkg = torch.tensor(inputs_Xbb_bkg['pf_points']).float().to(device)\n",
    "pf_features_bkg = torch.tensor(inputs_Xbb_bkg['pf_features']).float().to(device)\n",
    "pf_vectors_bkg = torch.tensor(inputs_Xbb_bkg['pf_vectors']).float().to(device)\n",
    "pf_mask_bkg = torch.tensor(inputs_Xbb_bkg['pf_mask']).float().to(device)\n",
    "\n",
    "preds_Xbb = model_Xbb(pf_points,pf_features,pf_vectors,pf_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_Xbb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxmap = helpers.get_idxmap('config/train.txt')\n",
    "idxmap_val = helpers.get_idxmap('config/val.txt')\n",
    "integer_file_map = helpers.create_integer_file_map(idxmap)\n",
    "integer_file_map_val = helpers.create_integer_file_map(idxmap_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Xbb.load_state_dict(torch.load('/Users/matthiasvigl/Xbb_lr0.01_bs512_subset0.1.pt',map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights :\n",
      "dict_keys(['mod.cls_token', 'mod.embed.input_bn.weight', 'mod.embed.input_bn.bias', 'mod.embed.input_bn.running_mean', 'mod.embed.input_bn.running_var', 'mod.embed.input_bn.num_batches_tracked', 'mod.embed.embed.0.weight', 'mod.embed.embed.0.bias', 'mod.embed.embed.1.weight', 'mod.embed.embed.1.bias', 'mod.embed.embed.3.weight', 'mod.embed.embed.3.bias', 'mod.embed.embed.4.weight', 'mod.embed.embed.4.bias', 'mod.embed.embed.6.weight', 'mod.embed.embed.6.bias', 'mod.embed.embed.7.weight', 'mod.embed.embed.7.bias', 'mod.pair_embed.embed.0.weight', 'mod.pair_embed.embed.0.bias', 'mod.pair_embed.embed.0.running_mean', 'mod.pair_embed.embed.0.running_var', 'mod.pair_embed.embed.0.num_batches_tracked', 'mod.pair_embed.embed.1.weight', 'mod.pair_embed.embed.1.bias', 'mod.pair_embed.embed.2.weight', 'mod.pair_embed.embed.2.bias', 'mod.pair_embed.embed.2.running_mean', 'mod.pair_embed.embed.2.running_var', 'mod.pair_embed.embed.2.num_batches_tracked', 'mod.pair_embed.embed.4.weight', 'mod.pair_embed.embed.4.bias', 'mod.pair_embed.embed.5.weight', 'mod.pair_embed.embed.5.bias', 'mod.pair_embed.embed.5.running_mean', 'mod.pair_embed.embed.5.running_var', 'mod.pair_embed.embed.5.num_batches_tracked', 'mod.pair_embed.embed.7.weight', 'mod.pair_embed.embed.7.bias', 'mod.pair_embed.embed.8.weight', 'mod.pair_embed.embed.8.bias', 'mod.pair_embed.embed.8.running_mean', 'mod.pair_embed.embed.8.running_var', 'mod.pair_embed.embed.8.num_batches_tracked', 'mod.pair_embed.embed.10.weight', 'mod.pair_embed.embed.10.bias', 'mod.pair_embed.embed.11.weight', 'mod.pair_embed.embed.11.bias', 'mod.pair_embed.embed.11.running_mean', 'mod.pair_embed.embed.11.running_var', 'mod.pair_embed.embed.11.num_batches_tracked', 'mod.blocks.0.c_attn', 'mod.blocks.0.w_resid', 'mod.blocks.0.pre_attn_norm.weight', 'mod.blocks.0.pre_attn_norm.bias', 'mod.blocks.0.attn.in_proj_weight', 'mod.blocks.0.attn.in_proj_bias', 'mod.blocks.0.attn.out_proj.weight', 'mod.blocks.0.attn.out_proj.bias', 'mod.blocks.0.post_attn_norm.weight', 'mod.blocks.0.post_attn_norm.bias', 'mod.blocks.0.pre_fc_norm.weight', 'mod.blocks.0.pre_fc_norm.bias', 'mod.blocks.0.fc1.weight', 'mod.blocks.0.fc1.bias', 'mod.blocks.0.post_fc_norm.weight', 'mod.blocks.0.post_fc_norm.bias', 'mod.blocks.0.fc2.weight', 'mod.blocks.0.fc2.bias', 'mod.blocks.1.c_attn', 'mod.blocks.1.w_resid', 'mod.blocks.1.pre_attn_norm.weight', 'mod.blocks.1.pre_attn_norm.bias', 'mod.blocks.1.attn.in_proj_weight', 'mod.blocks.1.attn.in_proj_bias', 'mod.blocks.1.attn.out_proj.weight', 'mod.blocks.1.attn.out_proj.bias', 'mod.blocks.1.post_attn_norm.weight', 'mod.blocks.1.post_attn_norm.bias', 'mod.blocks.1.pre_fc_norm.weight', 'mod.blocks.1.pre_fc_norm.bias', 'mod.blocks.1.fc1.weight', 'mod.blocks.1.fc1.bias', 'mod.blocks.1.post_fc_norm.weight', 'mod.blocks.1.post_fc_norm.bias', 'mod.blocks.1.fc2.weight', 'mod.blocks.1.fc2.bias', 'mod.blocks.2.c_attn', 'mod.blocks.2.w_resid', 'mod.blocks.2.pre_attn_norm.weight', 'mod.blocks.2.pre_attn_norm.bias', 'mod.blocks.2.attn.in_proj_weight', 'mod.blocks.2.attn.in_proj_bias', 'mod.blocks.2.attn.out_proj.weight', 'mod.blocks.2.attn.out_proj.bias', 'mod.blocks.2.post_attn_norm.weight', 'mod.blocks.2.post_attn_norm.bias', 'mod.blocks.2.pre_fc_norm.weight', 'mod.blocks.2.pre_fc_norm.bias', 'mod.blocks.2.fc1.weight', 'mod.blocks.2.fc1.bias', 'mod.blocks.2.post_fc_norm.weight', 'mod.blocks.2.post_fc_norm.bias', 'mod.blocks.2.fc2.weight', 'mod.blocks.2.fc2.bias', 'mod.blocks.3.c_attn', 'mod.blocks.3.w_resid', 'mod.blocks.3.pre_attn_norm.weight', 'mod.blocks.3.pre_attn_norm.bias', 'mod.blocks.3.attn.in_proj_weight', 'mod.blocks.3.attn.in_proj_bias', 'mod.blocks.3.attn.out_proj.weight', 'mod.blocks.3.attn.out_proj.bias', 'mod.blocks.3.post_attn_norm.weight', 'mod.blocks.3.post_attn_norm.bias', 'mod.blocks.3.pre_fc_norm.weight', 'mod.blocks.3.pre_fc_norm.bias', 'mod.blocks.3.fc1.weight', 'mod.blocks.3.fc1.bias', 'mod.blocks.3.post_fc_norm.weight', 'mod.blocks.3.post_fc_norm.bias', 'mod.blocks.3.fc2.weight', 'mod.blocks.3.fc2.bias', 'mod.blocks.4.c_attn', 'mod.blocks.4.w_resid', 'mod.blocks.4.pre_attn_norm.weight', 'mod.blocks.4.pre_attn_norm.bias', 'mod.blocks.4.attn.in_proj_weight', 'mod.blocks.4.attn.in_proj_bias', 'mod.blocks.4.attn.out_proj.weight', 'mod.blocks.4.attn.out_proj.bias', 'mod.blocks.4.post_attn_norm.weight', 'mod.blocks.4.post_attn_norm.bias', 'mod.blocks.4.pre_fc_norm.weight', 'mod.blocks.4.pre_fc_norm.bias', 'mod.blocks.4.fc1.weight', 'mod.blocks.4.fc1.bias', 'mod.blocks.4.post_fc_norm.weight', 'mod.blocks.4.post_fc_norm.bias', 'mod.blocks.4.fc2.weight', 'mod.blocks.4.fc2.bias', 'mod.blocks.5.c_attn', 'mod.blocks.5.w_resid', 'mod.blocks.5.pre_attn_norm.weight', 'mod.blocks.5.pre_attn_norm.bias', 'mod.blocks.5.attn.in_proj_weight', 'mod.blocks.5.attn.in_proj_bias', 'mod.blocks.5.attn.out_proj.weight', 'mod.blocks.5.attn.out_proj.bias', 'mod.blocks.5.post_attn_norm.weight', 'mod.blocks.5.post_attn_norm.bias', 'mod.blocks.5.pre_fc_norm.weight', 'mod.blocks.5.pre_fc_norm.bias', 'mod.blocks.5.fc1.weight', 'mod.blocks.5.fc1.bias', 'mod.blocks.5.post_fc_norm.weight', 'mod.blocks.5.post_fc_norm.bias', 'mod.blocks.5.fc2.weight', 'mod.blocks.5.fc2.bias', 'mod.blocks.6.c_attn', 'mod.blocks.6.w_resid', 'mod.blocks.6.pre_attn_norm.weight', 'mod.blocks.6.pre_attn_norm.bias', 'mod.blocks.6.attn.in_proj_weight', 'mod.blocks.6.attn.in_proj_bias', 'mod.blocks.6.attn.out_proj.weight', 'mod.blocks.6.attn.out_proj.bias', 'mod.blocks.6.post_attn_norm.weight', 'mod.blocks.6.post_attn_norm.bias', 'mod.blocks.6.pre_fc_norm.weight', 'mod.blocks.6.pre_fc_norm.bias', 'mod.blocks.6.fc1.weight', 'mod.blocks.6.fc1.bias', 'mod.blocks.6.post_fc_norm.weight', 'mod.blocks.6.post_fc_norm.bias', 'mod.blocks.6.fc2.weight', 'mod.blocks.6.fc2.bias', 'mod.blocks.7.c_attn', 'mod.blocks.7.w_resid', 'mod.blocks.7.pre_attn_norm.weight', 'mod.blocks.7.pre_attn_norm.bias', 'mod.blocks.7.attn.in_proj_weight', 'mod.blocks.7.attn.in_proj_bias', 'mod.blocks.7.attn.out_proj.weight', 'mod.blocks.7.attn.out_proj.bias', 'mod.blocks.7.post_attn_norm.weight', 'mod.blocks.7.post_attn_norm.bias', 'mod.blocks.7.pre_fc_norm.weight', 'mod.blocks.7.pre_fc_norm.bias', 'mod.blocks.7.fc1.weight', 'mod.blocks.7.fc1.bias', 'mod.blocks.7.post_fc_norm.weight', 'mod.blocks.7.post_fc_norm.bias', 'mod.blocks.7.fc2.weight', 'mod.blocks.7.fc2.bias', 'mod.cls_blocks.0.c_attn', 'mod.cls_blocks.0.w_resid', 'mod.cls_blocks.0.pre_attn_norm.weight', 'mod.cls_blocks.0.pre_attn_norm.bias', 'mod.cls_blocks.0.attn.in_proj_weight', 'mod.cls_blocks.0.attn.in_proj_bias', 'mod.cls_blocks.0.attn.out_proj.weight', 'mod.cls_blocks.0.attn.out_proj.bias', 'mod.cls_blocks.0.post_attn_norm.weight', 'mod.cls_blocks.0.post_attn_norm.bias', 'mod.cls_blocks.0.pre_fc_norm.weight', 'mod.cls_blocks.0.pre_fc_norm.bias', 'mod.cls_blocks.0.fc1.weight', 'mod.cls_blocks.0.fc1.bias', 'mod.cls_blocks.0.post_fc_norm.weight', 'mod.cls_blocks.0.post_fc_norm.bias', 'mod.cls_blocks.0.fc2.weight', 'mod.cls_blocks.0.fc2.bias', 'mod.cls_blocks.1.c_attn', 'mod.cls_blocks.1.w_resid', 'mod.cls_blocks.1.pre_attn_norm.weight', 'mod.cls_blocks.1.pre_attn_norm.bias', 'mod.cls_blocks.1.attn.in_proj_weight', 'mod.cls_blocks.1.attn.in_proj_bias', 'mod.cls_blocks.1.attn.out_proj.weight', 'mod.cls_blocks.1.attn.out_proj.bias', 'mod.cls_blocks.1.post_attn_norm.weight', 'mod.cls_blocks.1.post_attn_norm.bias', 'mod.cls_blocks.1.pre_fc_norm.weight', 'mod.cls_blocks.1.pre_fc_norm.bias', 'mod.cls_blocks.1.fc1.weight', 'mod.cls_blocks.1.fc1.bias', 'mod.cls_blocks.1.post_fc_norm.weight', 'mod.cls_blocks.1.post_fc_norm.bias', 'mod.cls_blocks.1.fc2.weight', 'mod.cls_blocks.1.fc2.bias', 'mod.norm.weight', 'mod.norm.bias'])\n",
      "loading weights :\n",
      "dict_keys(['mod.cls_token', 'mod.embed.input_bn.weight', 'mod.embed.input_bn.bias', 'mod.embed.input_bn.running_mean', 'mod.embed.input_bn.running_var', 'mod.embed.input_bn.num_batches_tracked', 'mod.embed.embed.0.weight', 'mod.embed.embed.0.bias', 'mod.embed.embed.1.weight', 'mod.embed.embed.1.bias', 'mod.embed.embed.3.weight', 'mod.embed.embed.3.bias', 'mod.embed.embed.4.weight', 'mod.embed.embed.4.bias', 'mod.embed.embed.6.weight', 'mod.embed.embed.6.bias', 'mod.embed.embed.7.weight', 'mod.embed.embed.7.bias', 'mod.pair_embed.embed.0.weight', 'mod.pair_embed.embed.0.bias', 'mod.pair_embed.embed.0.running_mean', 'mod.pair_embed.embed.0.running_var', 'mod.pair_embed.embed.0.num_batches_tracked', 'mod.pair_embed.embed.1.weight', 'mod.pair_embed.embed.1.bias', 'mod.pair_embed.embed.2.weight', 'mod.pair_embed.embed.2.bias', 'mod.pair_embed.embed.2.running_mean', 'mod.pair_embed.embed.2.running_var', 'mod.pair_embed.embed.2.num_batches_tracked', 'mod.pair_embed.embed.4.weight', 'mod.pair_embed.embed.4.bias', 'mod.pair_embed.embed.5.weight', 'mod.pair_embed.embed.5.bias', 'mod.pair_embed.embed.5.running_mean', 'mod.pair_embed.embed.5.running_var', 'mod.pair_embed.embed.5.num_batches_tracked', 'mod.pair_embed.embed.7.weight', 'mod.pair_embed.embed.7.bias', 'mod.pair_embed.embed.8.weight', 'mod.pair_embed.embed.8.bias', 'mod.pair_embed.embed.8.running_mean', 'mod.pair_embed.embed.8.running_var', 'mod.pair_embed.embed.8.num_batches_tracked', 'mod.pair_embed.embed.10.weight', 'mod.pair_embed.embed.10.bias', 'mod.pair_embed.embed.11.weight', 'mod.pair_embed.embed.11.bias', 'mod.pair_embed.embed.11.running_mean', 'mod.pair_embed.embed.11.running_var', 'mod.pair_embed.embed.11.num_batches_tracked', 'mod.blocks.0.c_attn', 'mod.blocks.0.w_resid', 'mod.blocks.0.pre_attn_norm.weight', 'mod.blocks.0.pre_attn_norm.bias', 'mod.blocks.0.attn.in_proj_weight', 'mod.blocks.0.attn.in_proj_bias', 'mod.blocks.0.attn.out_proj.weight', 'mod.blocks.0.attn.out_proj.bias', 'mod.blocks.0.post_attn_norm.weight', 'mod.blocks.0.post_attn_norm.bias', 'mod.blocks.0.pre_fc_norm.weight', 'mod.blocks.0.pre_fc_norm.bias', 'mod.blocks.0.fc1.weight', 'mod.blocks.0.fc1.bias', 'mod.blocks.0.post_fc_norm.weight', 'mod.blocks.0.post_fc_norm.bias', 'mod.blocks.0.fc2.weight', 'mod.blocks.0.fc2.bias', 'mod.blocks.1.c_attn', 'mod.blocks.1.w_resid', 'mod.blocks.1.pre_attn_norm.weight', 'mod.blocks.1.pre_attn_norm.bias', 'mod.blocks.1.attn.in_proj_weight', 'mod.blocks.1.attn.in_proj_bias', 'mod.blocks.1.attn.out_proj.weight', 'mod.blocks.1.attn.out_proj.bias', 'mod.blocks.1.post_attn_norm.weight', 'mod.blocks.1.post_attn_norm.bias', 'mod.blocks.1.pre_fc_norm.weight', 'mod.blocks.1.pre_fc_norm.bias', 'mod.blocks.1.fc1.weight', 'mod.blocks.1.fc1.bias', 'mod.blocks.1.post_fc_norm.weight', 'mod.blocks.1.post_fc_norm.bias', 'mod.blocks.1.fc2.weight', 'mod.blocks.1.fc2.bias', 'mod.blocks.2.c_attn', 'mod.blocks.2.w_resid', 'mod.blocks.2.pre_attn_norm.weight', 'mod.blocks.2.pre_attn_norm.bias', 'mod.blocks.2.attn.in_proj_weight', 'mod.blocks.2.attn.in_proj_bias', 'mod.blocks.2.attn.out_proj.weight', 'mod.blocks.2.attn.out_proj.bias', 'mod.blocks.2.post_attn_norm.weight', 'mod.blocks.2.post_attn_norm.bias', 'mod.blocks.2.pre_fc_norm.weight', 'mod.blocks.2.pre_fc_norm.bias', 'mod.blocks.2.fc1.weight', 'mod.blocks.2.fc1.bias', 'mod.blocks.2.post_fc_norm.weight', 'mod.blocks.2.post_fc_norm.bias', 'mod.blocks.2.fc2.weight', 'mod.blocks.2.fc2.bias', 'mod.blocks.3.c_attn', 'mod.blocks.3.w_resid', 'mod.blocks.3.pre_attn_norm.weight', 'mod.blocks.3.pre_attn_norm.bias', 'mod.blocks.3.attn.in_proj_weight', 'mod.blocks.3.attn.in_proj_bias', 'mod.blocks.3.attn.out_proj.weight', 'mod.blocks.3.attn.out_proj.bias', 'mod.blocks.3.post_attn_norm.weight', 'mod.blocks.3.post_attn_norm.bias', 'mod.blocks.3.pre_fc_norm.weight', 'mod.blocks.3.pre_fc_norm.bias', 'mod.blocks.3.fc1.weight', 'mod.blocks.3.fc1.bias', 'mod.blocks.3.post_fc_norm.weight', 'mod.blocks.3.post_fc_norm.bias', 'mod.blocks.3.fc2.weight', 'mod.blocks.3.fc2.bias', 'mod.blocks.4.c_attn', 'mod.blocks.4.w_resid', 'mod.blocks.4.pre_attn_norm.weight', 'mod.blocks.4.pre_attn_norm.bias', 'mod.blocks.4.attn.in_proj_weight', 'mod.blocks.4.attn.in_proj_bias', 'mod.blocks.4.attn.out_proj.weight', 'mod.blocks.4.attn.out_proj.bias', 'mod.blocks.4.post_attn_norm.weight', 'mod.blocks.4.post_attn_norm.bias', 'mod.blocks.4.pre_fc_norm.weight', 'mod.blocks.4.pre_fc_norm.bias', 'mod.blocks.4.fc1.weight', 'mod.blocks.4.fc1.bias', 'mod.blocks.4.post_fc_norm.weight', 'mod.blocks.4.post_fc_norm.bias', 'mod.blocks.4.fc2.weight', 'mod.blocks.4.fc2.bias', 'mod.blocks.5.c_attn', 'mod.blocks.5.w_resid', 'mod.blocks.5.pre_attn_norm.weight', 'mod.blocks.5.pre_attn_norm.bias', 'mod.blocks.5.attn.in_proj_weight', 'mod.blocks.5.attn.in_proj_bias', 'mod.blocks.5.attn.out_proj.weight', 'mod.blocks.5.attn.out_proj.bias', 'mod.blocks.5.post_attn_norm.weight', 'mod.blocks.5.post_attn_norm.bias', 'mod.blocks.5.pre_fc_norm.weight', 'mod.blocks.5.pre_fc_norm.bias', 'mod.blocks.5.fc1.weight', 'mod.blocks.5.fc1.bias', 'mod.blocks.5.post_fc_norm.weight', 'mod.blocks.5.post_fc_norm.bias', 'mod.blocks.5.fc2.weight', 'mod.blocks.5.fc2.bias', 'mod.blocks.6.c_attn', 'mod.blocks.6.w_resid', 'mod.blocks.6.pre_attn_norm.weight', 'mod.blocks.6.pre_attn_norm.bias', 'mod.blocks.6.attn.in_proj_weight', 'mod.blocks.6.attn.in_proj_bias', 'mod.blocks.6.attn.out_proj.weight', 'mod.blocks.6.attn.out_proj.bias', 'mod.blocks.6.post_attn_norm.weight', 'mod.blocks.6.post_attn_norm.bias', 'mod.blocks.6.pre_fc_norm.weight', 'mod.blocks.6.pre_fc_norm.bias', 'mod.blocks.6.fc1.weight', 'mod.blocks.6.fc1.bias', 'mod.blocks.6.post_fc_norm.weight', 'mod.blocks.6.post_fc_norm.bias', 'mod.blocks.6.fc2.weight', 'mod.blocks.6.fc2.bias', 'mod.blocks.7.c_attn', 'mod.blocks.7.w_resid', 'mod.blocks.7.pre_attn_norm.weight', 'mod.blocks.7.pre_attn_norm.bias', 'mod.blocks.7.attn.in_proj_weight', 'mod.blocks.7.attn.in_proj_bias', 'mod.blocks.7.attn.out_proj.weight', 'mod.blocks.7.attn.out_proj.bias', 'mod.blocks.7.post_attn_norm.weight', 'mod.blocks.7.post_attn_norm.bias', 'mod.blocks.7.pre_fc_norm.weight', 'mod.blocks.7.pre_fc_norm.bias', 'mod.blocks.7.fc1.weight', 'mod.blocks.7.fc1.bias', 'mod.blocks.7.post_fc_norm.weight', 'mod.blocks.7.post_fc_norm.bias', 'mod.blocks.7.fc2.weight', 'mod.blocks.7.fc2.bias', 'mod.cls_blocks.0.c_attn', 'mod.cls_blocks.0.w_resid', 'mod.cls_blocks.0.pre_attn_norm.weight', 'mod.cls_blocks.0.pre_attn_norm.bias', 'mod.cls_blocks.0.attn.in_proj_weight', 'mod.cls_blocks.0.attn.in_proj_bias', 'mod.cls_blocks.0.attn.out_proj.weight', 'mod.cls_blocks.0.attn.out_proj.bias', 'mod.cls_blocks.0.post_attn_norm.weight', 'mod.cls_blocks.0.post_attn_norm.bias', 'mod.cls_blocks.0.pre_fc_norm.weight', 'mod.cls_blocks.0.pre_fc_norm.bias', 'mod.cls_blocks.0.fc1.weight', 'mod.cls_blocks.0.fc1.bias', 'mod.cls_blocks.0.post_fc_norm.weight', 'mod.cls_blocks.0.post_fc_norm.bias', 'mod.cls_blocks.0.fc2.weight', 'mod.cls_blocks.0.fc2.bias', 'mod.cls_blocks.1.c_attn', 'mod.cls_blocks.1.w_resid', 'mod.cls_blocks.1.pre_attn_norm.weight', 'mod.cls_blocks.1.pre_attn_norm.bias', 'mod.cls_blocks.1.attn.in_proj_weight', 'mod.cls_blocks.1.attn.in_proj_bias', 'mod.cls_blocks.1.attn.out_proj.weight', 'mod.cls_blocks.1.attn.out_proj.bias', 'mod.cls_blocks.1.post_attn_norm.weight', 'mod.cls_blocks.1.post_attn_norm.bias', 'mod.cls_blocks.1.pre_fc_norm.weight', 'mod.cls_blocks.1.pre_fc_norm.bias', 'mod.cls_blocks.1.fc1.weight', 'mod.cls_blocks.1.fc1.bias', 'mod.cls_blocks.1.post_fc_norm.weight', 'mod.cls_blocks.1.post_fc_norm.bias', 'mod.cls_blocks.1.fc2.weight', 'mod.cls_blocks.1.fc2.bias', 'mod.norm.weight', 'mod.norm.bias'])\n",
      "loading weights :\n",
      "dict_keys(['Xbb.0.weight', 'Xbb.0.bias', 'mod.cls_token', 'mod.embed.input_bn.weight', 'mod.embed.input_bn.bias', 'mod.embed.input_bn.running_mean', 'mod.embed.input_bn.running_var', 'mod.embed.input_bn.num_batches_tracked', 'mod.embed.embed.0.weight', 'mod.embed.embed.0.bias', 'mod.embed.embed.1.weight', 'mod.embed.embed.1.bias', 'mod.embed.embed.3.weight', 'mod.embed.embed.3.bias', 'mod.embed.embed.4.weight', 'mod.embed.embed.4.bias', 'mod.embed.embed.6.weight', 'mod.embed.embed.6.bias', 'mod.embed.embed.7.weight', 'mod.embed.embed.7.bias', 'mod.pair_embed.embed.0.weight', 'mod.pair_embed.embed.0.bias', 'mod.pair_embed.embed.0.running_mean', 'mod.pair_embed.embed.0.running_var', 'mod.pair_embed.embed.0.num_batches_tracked', 'mod.pair_embed.embed.1.weight', 'mod.pair_embed.embed.1.bias', 'mod.pair_embed.embed.2.weight', 'mod.pair_embed.embed.2.bias', 'mod.pair_embed.embed.2.running_mean', 'mod.pair_embed.embed.2.running_var', 'mod.pair_embed.embed.2.num_batches_tracked', 'mod.pair_embed.embed.4.weight', 'mod.pair_embed.embed.4.bias', 'mod.pair_embed.embed.5.weight', 'mod.pair_embed.embed.5.bias', 'mod.pair_embed.embed.5.running_mean', 'mod.pair_embed.embed.5.running_var', 'mod.pair_embed.embed.5.num_batches_tracked', 'mod.pair_embed.embed.7.weight', 'mod.pair_embed.embed.7.bias', 'mod.pair_embed.embed.8.weight', 'mod.pair_embed.embed.8.bias', 'mod.pair_embed.embed.8.running_mean', 'mod.pair_embed.embed.8.running_var', 'mod.pair_embed.embed.8.num_batches_tracked', 'mod.pair_embed.embed.10.weight', 'mod.pair_embed.embed.10.bias', 'mod.pair_embed.embed.11.weight', 'mod.pair_embed.embed.11.bias', 'mod.pair_embed.embed.11.running_mean', 'mod.pair_embed.embed.11.running_var', 'mod.pair_embed.embed.11.num_batches_tracked', 'mod.blocks.0.c_attn', 'mod.blocks.0.w_resid', 'mod.blocks.0.pre_attn_norm.weight', 'mod.blocks.0.pre_attn_norm.bias', 'mod.blocks.0.attn.in_proj_weight', 'mod.blocks.0.attn.in_proj_bias', 'mod.blocks.0.attn.out_proj.weight', 'mod.blocks.0.attn.out_proj.bias', 'mod.blocks.0.post_attn_norm.weight', 'mod.blocks.0.post_attn_norm.bias', 'mod.blocks.0.pre_fc_norm.weight', 'mod.blocks.0.pre_fc_norm.bias', 'mod.blocks.0.fc1.weight', 'mod.blocks.0.fc1.bias', 'mod.blocks.0.post_fc_norm.weight', 'mod.blocks.0.post_fc_norm.bias', 'mod.blocks.0.fc2.weight', 'mod.blocks.0.fc2.bias', 'mod.blocks.1.c_attn', 'mod.blocks.1.w_resid', 'mod.blocks.1.pre_attn_norm.weight', 'mod.blocks.1.pre_attn_norm.bias', 'mod.blocks.1.attn.in_proj_weight', 'mod.blocks.1.attn.in_proj_bias', 'mod.blocks.1.attn.out_proj.weight', 'mod.blocks.1.attn.out_proj.bias', 'mod.blocks.1.post_attn_norm.weight', 'mod.blocks.1.post_attn_norm.bias', 'mod.blocks.1.pre_fc_norm.weight', 'mod.blocks.1.pre_fc_norm.bias', 'mod.blocks.1.fc1.weight', 'mod.blocks.1.fc1.bias', 'mod.blocks.1.post_fc_norm.weight', 'mod.blocks.1.post_fc_norm.bias', 'mod.blocks.1.fc2.weight', 'mod.blocks.1.fc2.bias', 'mod.blocks.2.c_attn', 'mod.blocks.2.w_resid', 'mod.blocks.2.pre_attn_norm.weight', 'mod.blocks.2.pre_attn_norm.bias', 'mod.blocks.2.attn.in_proj_weight', 'mod.blocks.2.attn.in_proj_bias', 'mod.blocks.2.attn.out_proj.weight', 'mod.blocks.2.attn.out_proj.bias', 'mod.blocks.2.post_attn_norm.weight', 'mod.blocks.2.post_attn_norm.bias', 'mod.blocks.2.pre_fc_norm.weight', 'mod.blocks.2.pre_fc_norm.bias', 'mod.blocks.2.fc1.weight', 'mod.blocks.2.fc1.bias', 'mod.blocks.2.post_fc_norm.weight', 'mod.blocks.2.post_fc_norm.bias', 'mod.blocks.2.fc2.weight', 'mod.blocks.2.fc2.bias', 'mod.blocks.3.c_attn', 'mod.blocks.3.w_resid', 'mod.blocks.3.pre_attn_norm.weight', 'mod.blocks.3.pre_attn_norm.bias', 'mod.blocks.3.attn.in_proj_weight', 'mod.blocks.3.attn.in_proj_bias', 'mod.blocks.3.attn.out_proj.weight', 'mod.blocks.3.attn.out_proj.bias', 'mod.blocks.3.post_attn_norm.weight', 'mod.blocks.3.post_attn_norm.bias', 'mod.blocks.3.pre_fc_norm.weight', 'mod.blocks.3.pre_fc_norm.bias', 'mod.blocks.3.fc1.weight', 'mod.blocks.3.fc1.bias', 'mod.blocks.3.post_fc_norm.weight', 'mod.blocks.3.post_fc_norm.bias', 'mod.blocks.3.fc2.weight', 'mod.blocks.3.fc2.bias', 'mod.blocks.4.c_attn', 'mod.blocks.4.w_resid', 'mod.blocks.4.pre_attn_norm.weight', 'mod.blocks.4.pre_attn_norm.bias', 'mod.blocks.4.attn.in_proj_weight', 'mod.blocks.4.attn.in_proj_bias', 'mod.blocks.4.attn.out_proj.weight', 'mod.blocks.4.attn.out_proj.bias', 'mod.blocks.4.post_attn_norm.weight', 'mod.blocks.4.post_attn_norm.bias', 'mod.blocks.4.pre_fc_norm.weight', 'mod.blocks.4.pre_fc_norm.bias', 'mod.blocks.4.fc1.weight', 'mod.blocks.4.fc1.bias', 'mod.blocks.4.post_fc_norm.weight', 'mod.blocks.4.post_fc_norm.bias', 'mod.blocks.4.fc2.weight', 'mod.blocks.4.fc2.bias', 'mod.blocks.5.c_attn', 'mod.blocks.5.w_resid', 'mod.blocks.5.pre_attn_norm.weight', 'mod.blocks.5.pre_attn_norm.bias', 'mod.blocks.5.attn.in_proj_weight', 'mod.blocks.5.attn.in_proj_bias', 'mod.blocks.5.attn.out_proj.weight', 'mod.blocks.5.attn.out_proj.bias', 'mod.blocks.5.post_attn_norm.weight', 'mod.blocks.5.post_attn_norm.bias', 'mod.blocks.5.pre_fc_norm.weight', 'mod.blocks.5.pre_fc_norm.bias', 'mod.blocks.5.fc1.weight', 'mod.blocks.5.fc1.bias', 'mod.blocks.5.post_fc_norm.weight', 'mod.blocks.5.post_fc_norm.bias', 'mod.blocks.5.fc2.weight', 'mod.blocks.5.fc2.bias', 'mod.blocks.6.c_attn', 'mod.blocks.6.w_resid', 'mod.blocks.6.pre_attn_norm.weight', 'mod.blocks.6.pre_attn_norm.bias', 'mod.blocks.6.attn.in_proj_weight', 'mod.blocks.6.attn.in_proj_bias', 'mod.blocks.6.attn.out_proj.weight', 'mod.blocks.6.attn.out_proj.bias', 'mod.blocks.6.post_attn_norm.weight', 'mod.blocks.6.post_attn_norm.bias', 'mod.blocks.6.pre_fc_norm.weight', 'mod.blocks.6.pre_fc_norm.bias', 'mod.blocks.6.fc1.weight', 'mod.blocks.6.fc1.bias', 'mod.blocks.6.post_fc_norm.weight', 'mod.blocks.6.post_fc_norm.bias', 'mod.blocks.6.fc2.weight', 'mod.blocks.6.fc2.bias', 'mod.blocks.7.c_attn', 'mod.blocks.7.w_resid', 'mod.blocks.7.pre_attn_norm.weight', 'mod.blocks.7.pre_attn_norm.bias', 'mod.blocks.7.attn.in_proj_weight', 'mod.blocks.7.attn.in_proj_bias', 'mod.blocks.7.attn.out_proj.weight', 'mod.blocks.7.attn.out_proj.bias', 'mod.blocks.7.post_attn_norm.weight', 'mod.blocks.7.post_attn_norm.bias', 'mod.blocks.7.pre_fc_norm.weight', 'mod.blocks.7.pre_fc_norm.bias', 'mod.blocks.7.fc1.weight', 'mod.blocks.7.fc1.bias', 'mod.blocks.7.post_fc_norm.weight', 'mod.blocks.7.post_fc_norm.bias', 'mod.blocks.7.fc2.weight', 'mod.blocks.7.fc2.bias', 'mod.cls_blocks.0.c_attn', 'mod.cls_blocks.0.w_resid', 'mod.cls_blocks.0.pre_attn_norm.weight', 'mod.cls_blocks.0.pre_attn_norm.bias', 'mod.cls_blocks.0.attn.in_proj_weight', 'mod.cls_blocks.0.attn.in_proj_bias', 'mod.cls_blocks.0.attn.out_proj.weight', 'mod.cls_blocks.0.attn.out_proj.bias', 'mod.cls_blocks.0.post_attn_norm.weight', 'mod.cls_blocks.0.post_attn_norm.bias', 'mod.cls_blocks.0.pre_fc_norm.weight', 'mod.cls_blocks.0.pre_fc_norm.bias', 'mod.cls_blocks.0.fc1.weight', 'mod.cls_blocks.0.fc1.bias', 'mod.cls_blocks.0.post_fc_norm.weight', 'mod.cls_blocks.0.post_fc_norm.bias', 'mod.cls_blocks.0.fc2.weight', 'mod.cls_blocks.0.fc2.bias', 'mod.cls_blocks.1.c_attn', 'mod.cls_blocks.1.w_resid', 'mod.cls_blocks.1.pre_attn_norm.weight', 'mod.cls_blocks.1.pre_attn_norm.bias', 'mod.cls_blocks.1.attn.in_proj_weight', 'mod.cls_blocks.1.attn.in_proj_bias', 'mod.cls_blocks.1.attn.out_proj.weight', 'mod.cls_blocks.1.attn.out_proj.bias', 'mod.cls_blocks.1.post_attn_norm.weight', 'mod.cls_blocks.1.post_attn_norm.bias', 'mod.cls_blocks.1.pre_fc_norm.weight', 'mod.cls_blocks.1.pre_fc_norm.bias', 'mod.cls_blocks.1.fc1.weight', 'mod.cls_blocks.1.fc1.bias', 'mod.cls_blocks.1.post_fc_norm.weight', 'mod.cls_blocks.1.post_fc_norm.bias', 'mod.cls_blocks.1.fc2.weight', 'mod.cls_blocks.1.fc2.bias', 'mod.norm.weight', 'mod.norm.bias'])\n",
      "loading weights :\n",
      "dict_keys(['Xbb.0.weight', 'Xbb.0.bias', 'mod.cls_token', 'mod.embed.input_bn.weight', 'mod.embed.input_bn.bias', 'mod.embed.input_bn.running_mean', 'mod.embed.input_bn.running_var', 'mod.embed.input_bn.num_batches_tracked', 'mod.embed.embed.0.weight', 'mod.embed.embed.0.bias', 'mod.embed.embed.1.weight', 'mod.embed.embed.1.bias', 'mod.embed.embed.3.weight', 'mod.embed.embed.3.bias', 'mod.embed.embed.4.weight', 'mod.embed.embed.4.bias', 'mod.embed.embed.6.weight', 'mod.embed.embed.6.bias', 'mod.embed.embed.7.weight', 'mod.embed.embed.7.bias', 'mod.pair_embed.embed.0.weight', 'mod.pair_embed.embed.0.bias', 'mod.pair_embed.embed.0.running_mean', 'mod.pair_embed.embed.0.running_var', 'mod.pair_embed.embed.0.num_batches_tracked', 'mod.pair_embed.embed.1.weight', 'mod.pair_embed.embed.1.bias', 'mod.pair_embed.embed.2.weight', 'mod.pair_embed.embed.2.bias', 'mod.pair_embed.embed.2.running_mean', 'mod.pair_embed.embed.2.running_var', 'mod.pair_embed.embed.2.num_batches_tracked', 'mod.pair_embed.embed.4.weight', 'mod.pair_embed.embed.4.bias', 'mod.pair_embed.embed.5.weight', 'mod.pair_embed.embed.5.bias', 'mod.pair_embed.embed.5.running_mean', 'mod.pair_embed.embed.5.running_var', 'mod.pair_embed.embed.5.num_batches_tracked', 'mod.pair_embed.embed.7.weight', 'mod.pair_embed.embed.7.bias', 'mod.pair_embed.embed.8.weight', 'mod.pair_embed.embed.8.bias', 'mod.pair_embed.embed.8.running_mean', 'mod.pair_embed.embed.8.running_var', 'mod.pair_embed.embed.8.num_batches_tracked', 'mod.pair_embed.embed.10.weight', 'mod.pair_embed.embed.10.bias', 'mod.pair_embed.embed.11.weight', 'mod.pair_embed.embed.11.bias', 'mod.pair_embed.embed.11.running_mean', 'mod.pair_embed.embed.11.running_var', 'mod.pair_embed.embed.11.num_batches_tracked', 'mod.blocks.0.c_attn', 'mod.blocks.0.w_resid', 'mod.blocks.0.pre_attn_norm.weight', 'mod.blocks.0.pre_attn_norm.bias', 'mod.blocks.0.attn.in_proj_weight', 'mod.blocks.0.attn.in_proj_bias', 'mod.blocks.0.attn.out_proj.weight', 'mod.blocks.0.attn.out_proj.bias', 'mod.blocks.0.post_attn_norm.weight', 'mod.blocks.0.post_attn_norm.bias', 'mod.blocks.0.pre_fc_norm.weight', 'mod.blocks.0.pre_fc_norm.bias', 'mod.blocks.0.fc1.weight', 'mod.blocks.0.fc1.bias', 'mod.blocks.0.post_fc_norm.weight', 'mod.blocks.0.post_fc_norm.bias', 'mod.blocks.0.fc2.weight', 'mod.blocks.0.fc2.bias', 'mod.blocks.1.c_attn', 'mod.blocks.1.w_resid', 'mod.blocks.1.pre_attn_norm.weight', 'mod.blocks.1.pre_attn_norm.bias', 'mod.blocks.1.attn.in_proj_weight', 'mod.blocks.1.attn.in_proj_bias', 'mod.blocks.1.attn.out_proj.weight', 'mod.blocks.1.attn.out_proj.bias', 'mod.blocks.1.post_attn_norm.weight', 'mod.blocks.1.post_attn_norm.bias', 'mod.blocks.1.pre_fc_norm.weight', 'mod.blocks.1.pre_fc_norm.bias', 'mod.blocks.1.fc1.weight', 'mod.blocks.1.fc1.bias', 'mod.blocks.1.post_fc_norm.weight', 'mod.blocks.1.post_fc_norm.bias', 'mod.blocks.1.fc2.weight', 'mod.blocks.1.fc2.bias', 'mod.blocks.2.c_attn', 'mod.blocks.2.w_resid', 'mod.blocks.2.pre_attn_norm.weight', 'mod.blocks.2.pre_attn_norm.bias', 'mod.blocks.2.attn.in_proj_weight', 'mod.blocks.2.attn.in_proj_bias', 'mod.blocks.2.attn.out_proj.weight', 'mod.blocks.2.attn.out_proj.bias', 'mod.blocks.2.post_attn_norm.weight', 'mod.blocks.2.post_attn_norm.bias', 'mod.blocks.2.pre_fc_norm.weight', 'mod.blocks.2.pre_fc_norm.bias', 'mod.blocks.2.fc1.weight', 'mod.blocks.2.fc1.bias', 'mod.blocks.2.post_fc_norm.weight', 'mod.blocks.2.post_fc_norm.bias', 'mod.blocks.2.fc2.weight', 'mod.blocks.2.fc2.bias', 'mod.blocks.3.c_attn', 'mod.blocks.3.w_resid', 'mod.blocks.3.pre_attn_norm.weight', 'mod.blocks.3.pre_attn_norm.bias', 'mod.blocks.3.attn.in_proj_weight', 'mod.blocks.3.attn.in_proj_bias', 'mod.blocks.3.attn.out_proj.weight', 'mod.blocks.3.attn.out_proj.bias', 'mod.blocks.3.post_attn_norm.weight', 'mod.blocks.3.post_attn_norm.bias', 'mod.blocks.3.pre_fc_norm.weight', 'mod.blocks.3.pre_fc_norm.bias', 'mod.blocks.3.fc1.weight', 'mod.blocks.3.fc1.bias', 'mod.blocks.3.post_fc_norm.weight', 'mod.blocks.3.post_fc_norm.bias', 'mod.blocks.3.fc2.weight', 'mod.blocks.3.fc2.bias', 'mod.blocks.4.c_attn', 'mod.blocks.4.w_resid', 'mod.blocks.4.pre_attn_norm.weight', 'mod.blocks.4.pre_attn_norm.bias', 'mod.blocks.4.attn.in_proj_weight', 'mod.blocks.4.attn.in_proj_bias', 'mod.blocks.4.attn.out_proj.weight', 'mod.blocks.4.attn.out_proj.bias', 'mod.blocks.4.post_attn_norm.weight', 'mod.blocks.4.post_attn_norm.bias', 'mod.blocks.4.pre_fc_norm.weight', 'mod.blocks.4.pre_fc_norm.bias', 'mod.blocks.4.fc1.weight', 'mod.blocks.4.fc1.bias', 'mod.blocks.4.post_fc_norm.weight', 'mod.blocks.4.post_fc_norm.bias', 'mod.blocks.4.fc2.weight', 'mod.blocks.4.fc2.bias', 'mod.blocks.5.c_attn', 'mod.blocks.5.w_resid', 'mod.blocks.5.pre_attn_norm.weight', 'mod.blocks.5.pre_attn_norm.bias', 'mod.blocks.5.attn.in_proj_weight', 'mod.blocks.5.attn.in_proj_bias', 'mod.blocks.5.attn.out_proj.weight', 'mod.blocks.5.attn.out_proj.bias', 'mod.blocks.5.post_attn_norm.weight', 'mod.blocks.5.post_attn_norm.bias', 'mod.blocks.5.pre_fc_norm.weight', 'mod.blocks.5.pre_fc_norm.bias', 'mod.blocks.5.fc1.weight', 'mod.blocks.5.fc1.bias', 'mod.blocks.5.post_fc_norm.weight', 'mod.blocks.5.post_fc_norm.bias', 'mod.blocks.5.fc2.weight', 'mod.blocks.5.fc2.bias', 'mod.blocks.6.c_attn', 'mod.blocks.6.w_resid', 'mod.blocks.6.pre_attn_norm.weight', 'mod.blocks.6.pre_attn_norm.bias', 'mod.blocks.6.attn.in_proj_weight', 'mod.blocks.6.attn.in_proj_bias', 'mod.blocks.6.attn.out_proj.weight', 'mod.blocks.6.attn.out_proj.bias', 'mod.blocks.6.post_attn_norm.weight', 'mod.blocks.6.post_attn_norm.bias', 'mod.blocks.6.pre_fc_norm.weight', 'mod.blocks.6.pre_fc_norm.bias', 'mod.blocks.6.fc1.weight', 'mod.blocks.6.fc1.bias', 'mod.blocks.6.post_fc_norm.weight', 'mod.blocks.6.post_fc_norm.bias', 'mod.blocks.6.fc2.weight', 'mod.blocks.6.fc2.bias', 'mod.blocks.7.c_attn', 'mod.blocks.7.w_resid', 'mod.blocks.7.pre_attn_norm.weight', 'mod.blocks.7.pre_attn_norm.bias', 'mod.blocks.7.attn.in_proj_weight', 'mod.blocks.7.attn.in_proj_bias', 'mod.blocks.7.attn.out_proj.weight', 'mod.blocks.7.attn.out_proj.bias', 'mod.blocks.7.post_attn_norm.weight', 'mod.blocks.7.post_attn_norm.bias', 'mod.blocks.7.pre_fc_norm.weight', 'mod.blocks.7.pre_fc_norm.bias', 'mod.blocks.7.fc1.weight', 'mod.blocks.7.fc1.bias', 'mod.blocks.7.post_fc_norm.weight', 'mod.blocks.7.post_fc_norm.bias', 'mod.blocks.7.fc2.weight', 'mod.blocks.7.fc2.bias', 'mod.cls_blocks.0.c_attn', 'mod.cls_blocks.0.w_resid', 'mod.cls_blocks.0.pre_attn_norm.weight', 'mod.cls_blocks.0.pre_attn_norm.bias', 'mod.cls_blocks.0.attn.in_proj_weight', 'mod.cls_blocks.0.attn.in_proj_bias', 'mod.cls_blocks.0.attn.out_proj.weight', 'mod.cls_blocks.0.attn.out_proj.bias', 'mod.cls_blocks.0.post_attn_norm.weight', 'mod.cls_blocks.0.post_attn_norm.bias', 'mod.cls_blocks.0.pre_fc_norm.weight', 'mod.cls_blocks.0.pre_fc_norm.bias', 'mod.cls_blocks.0.fc1.weight', 'mod.cls_blocks.0.fc1.bias', 'mod.cls_blocks.0.post_fc_norm.weight', 'mod.cls_blocks.0.post_fc_norm.bias', 'mod.cls_blocks.0.fc2.weight', 'mod.cls_blocks.0.fc2.bias', 'mod.cls_blocks.1.c_attn', 'mod.cls_blocks.1.w_resid', 'mod.cls_blocks.1.pre_attn_norm.weight', 'mod.cls_blocks.1.pre_attn_norm.bias', 'mod.cls_blocks.1.attn.in_proj_weight', 'mod.cls_blocks.1.attn.in_proj_bias', 'mod.cls_blocks.1.attn.out_proj.weight', 'mod.cls_blocks.1.attn.out_proj.bias', 'mod.cls_blocks.1.post_attn_norm.weight', 'mod.cls_blocks.1.post_attn_norm.bias', 'mod.cls_blocks.1.pre_fc_norm.weight', 'mod.cls_blocks.1.pre_fc_norm.bias', 'mod.cls_blocks.1.fc1.weight', 'mod.cls_blocks.1.fc1.bias', 'mod.cls_blocks.1.post_fc_norm.weight', 'mod.cls_blocks.1.post_fc_norm.bias', 'mod.cls_blocks.1.fc2.weight', 'mod.cls_blocks.1.fc2.bias', 'mod.norm.weight', 'mod.norm.bias'])\n"
     ]
    }
   ],
   "source": [
    "model_latent = helpers.load_weights(model_latent,'/Users/matthiasvigl/Xbb_lr0.01_bs512_subset0.1.pt',device)\n",
    "model_latent_hlf = helpers.load_weights(model_latent_hlf,'/Users/matthiasvigl/Xbb_lr0.01_bs512_subset0.1.pt',device)\n",
    "model_Xbb_hlf = helpers.load_weights(model_Xbb_hlf,'/Users/matthiasvigl/Xbb_lr0.01_bs512_subset0.1.pt',device)\n",
    "model_Xbb = helpers.load_weights(model_Xbb,'/Users/matthiasvigl/Xbb_lr0.01_bs512_subset0.1.pt',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_Xbb.eval()\n",
    "    preds_Xbb = model_Xbb(pf_points,pf_features,pf_vectors,pf_mask)\n",
    "    preds_Xbb_bkg = model_Xbb(pf_points_bkg,pf_features_bkg,pf_vectors_bkg,pf_mask_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b=np.linspace(0,1,101)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(preds_Xbb.detach().numpy(), lw=0.8,bins=b,histtype='step', density=True, alpha=0.7)\n",
    "ax.hist(preds_Xbb_bkg.detach().numpy(), lw=0.8,bins=b,histtype='step', density=True, alpha=0.7)\n",
    "ax.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/Users/matthiasvigl/Data_test_bkg_100.h5', 'r') as sample:\n",
    "    Xbb_scores = {}\n",
    "    Xbb_scores['Xbb_score'] = sample['Xbb_score'][:]\n",
    "    Xbb_scores['Xbb_label'] = sample['Xbb_label'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(Xbb_scores['Xbb_label'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35359, 5, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xbb_scores['Xbb_score'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGdCAYAAADJ6dNTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhxUlEQVR4nO3df2yV5f3/8VfPaU9b9ilHWWOhs0h0QVeFkkFhqEQwTQgubG5k8okLq2TDLZ4ui41sODdq5g+IM3xJzL0R3RjL4gZjU1wGYT+6GabDUIEyY9WNUV2Na5U4OVC7/jjn+v7hp8e2nP44p+c+57rOeT6Sk3Du3uecdy/rfb/OdV/3dRUZY4wAAAAsEch1AQAAACMRTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAVinOdQGpisfjeuutt1RRUaGioqJclwMAAKbAGKPz58+rurpagcDEfSPOhZO33npLNTU1uS4DAACkoaurS5dffvmE+zgXTioqKiR98MvNnDkzx9UAAICpiEajqqmpSZzHJ+JcOBm+lDNz5kzCCQAAjpnKkAwGxAIAAKs4E048z1Ntba3q6+tzXQoAAPBRkTHG5LqIVESjUYXDYZ07d47LOgAAOCKV87czPScAAKAwEE4AAIBVCCcAAMAqzoQTBsQCAFAYGBALAAB8x4BYAADgLMIJAACwCuEEAABYhXACAACs4tzCf34bGIorFv9wjHAwUKRQMRkOAIBscSaceJ4nz/MUi8V8+4yBobi2/PpvOtc3mNgWLi/R9nULCSgAAGSJM+EkEokoEokkbkXyQyxudK5vUN//Qp3KS4LqG4xp8/5To3pSAACAv5wJJ9lUXhJUeSiY6zIAAChIXKsAAABWIZwAAACrEE4AAIBVCCcAAMAqhBMAAGAVZ8KJ53mqra1VfX19rksBAAA+ciacRCIRdXR0qK2tLdelAAAAHzkTTgAAQGEgnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArOJMOGGGWAAACoMz4YQZYgEAKAzOhBMAAFAYCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCrOhBPW1gEAoDA4E05YWwcAgMLgTDgBAACFgXACAACsQjgBAABWIZwAAACrEE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsIoz4cTzPNXW1qq+vj7XpQAAAB85E04ikYg6OjrU1taW61IAAICPnAknAACgMBBOAACAVQgnAADAKoQTAABgFcIJAACwCuEEAABYhXACAACsQjgBAABWIZwAAACrEE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWCVn4eT999/XFVdcoXvuuSdXJQAAAAvlLJw89NBD+tSnPpWrjwcAAJbKSTj5xz/+oVdffVVr1qzJxccDAACLpRxOjhw5orVr16q6ulpFRUU6cODARft4nqd58+aprKxMy5Yt07Fjx0b9/J577tG2bdvSLhoAAOSvlMNJb2+v6urq5Hle0p/v27dPzc3Namlp0YkTJ1RXV6fVq1fr7bffliQ988wzmj9/vubPnz+9ygEAQF4qTvUFa9asmfByzI4dO7Rp0yZt3LhRkrRr1y4dPHhQu3fv1pYtW/TCCy9o79692r9/vy5cuKDBwUHNnDlTW7duTfp+/f396u/vTzyPRqOplgwAAByS0TEnAwMDOn78uBoaGj78gEBADQ0NOnr0qCRp27Zt6urq0uuvv65HH31UmzZtGjeYDO8fDocTj5qamkyWDAAALJPRcHL27FnFYjFVVVWN2l5VVaXu7u603vPee+/VuXPnEo+urq5MlAoAACyV8mWdTLrjjjsm3ae0tFSlpaX+FwMAAKyQ0Z6TyspKBYNB9fT0jNre09Oj2bNnZ/KjAABAnspoOAmFQlq8eLFaW1sT2+LxuFpbW7V8+fJpvbfneaqtrVV9ff10ywQAABZL+bLOhQsXdPr06cTzzs5Otbe3a9asWZo7d66am5vV2NioJUuWaOnSpdq5c6d6e3sTd++kKxKJKBKJKBqNKhwOT+u9AACAvVIOJy+++KJWrVqVeN7c3CxJamxs1J49e7R+/Xq988472rp1q7q7u7Vo0SIdPnz4okGyAAAAyaQcTlauXCljzIT7NDU1qampKe2iAABA4crZwn8AAADJEE4AAIBVnAkn3K0DAEBhcCacRCIRdXR0qK2tLdelAAAAHzkTTgAAQGEgnAAAAKsQTgAAgFWcCScMiAUAoDA4E04YEAsAQGFwJpwAAIDCQDgBAABWSXltnULUNxgb9TwYKFKomFwHAIAfCCcTCAaKFC4v0eb9p0ZtD5eXaPu6hQQUAAB8QDiZQKg4oO3rFioW/3AV5r7BmDbvPzVqGwAAyBxnwonnefI8T7FYbPKdM4jeEQAAssuZMy+3EgMAUBicCScAAKAwEE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFjFmXDieZ5qa2tVX1+f61IAAICPnAknzHMCAEBhcCacAACAwkA4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABgFcIJAACwCuEEAABYxZlwwgyxAAAUBmfCCTPEAgBQGJwJJwAAoDAQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVZwJJ6ytAwBAYXAmnLC2DgAAhcGZcAIAAAoD4QQAAFilONcFuKpvMJb4dzBQpFAxOQ8AgEwgnKQoGChSuLxEm/efSmwLl5do+7qFBBQAADKAcJKiUHFA29ctVCxuJH3Qg7J5/6nEcwAAMD2EkzTQQwIAgH84ywIAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVZwJJ57nqba2VvX19bkuBQAA+MiZcBKJRNTR0aG2trZclwIAAHzkTDgBAACFgXACAACsQjgBAABWIZwAAACrEE4AAIBVCCcAAMAqxbkuIF/0DcZGPQ8GihQqJvsBAJAqwsk0BQNFCpeXaPP+U6O2h8tLtH3dQgIKAAApIpxMU6g4oO3rFioWN4ltfYMxbd5/atQ2AAAwNYSTDKB3BACAzOGsCgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABgFcIJAACwCuEEAABYhXACAACsQjgBAABWIZwAAACrsLaOj/oGY4l/BwNFrMEDAMAUZD2cvPfee2poaNDQ0JCGhob0jW98Q5s2bcp2Gb4KBooULi/R5v2nEtvC5SXavm4hAQUAgElkPZxUVFToyJEjmjFjhnp7e3Xdddfp85//vD760Y9muxTfhIoD2r5uoWJxI+mDHpTN+08lngMAgPFlPZwEg0HNmDFDktTf3y9jjIzJv5M2PSQAAKQn5TPokSNHtHbtWlVXV6uoqEgHDhy4aB/P8zRv3jyVlZVp2bJlOnbs2Kifv/fee6qrq9Pll1+uzZs3q7KyMu1fAAAA5JeUw0lvb6/q6urkeV7Sn+/bt0/Nzc1qaWnRiRMnVFdXp9WrV+vtt99O7HPJJZfo1KlT6uzs1M9//nP19PSk/xsAAIC8knI4WbNmjR588EF97nOfS/rzHTt2aNOmTdq4caNqa2u1a9cuzZgxQ7t3775o36qqKtXV1ekvf/nLuJ/X39+vaDQ66gEAAPJXRgdGDAwM6Pjx42poaPjwAwIBNTQ06OjRo5Kknp4enT9/XpJ07tw5HTlyRFdfffW477lt2zaFw+HEo6amJpMlAwAAy2Q0nJw9e1axWExVVVWjtldVVam7u1uS9MYbb2jFihWqq6vTihUr9PWvf10LFiwY9z3vvfdenTt3LvHo6urKZMkAAMAyWb9bZ+nSpWpvb5/y/qWlpSotLfWvIAAAYJWM9pxUVlYqGAxeNMC1p6dHs2fPzuRHAQCAPJXRcBIKhbR48WK1trYmtsXjcbW2tmr58uXTem/P81RbW6v6+vrplgkAACyW8mWdCxcu6PTp04nnnZ2dam9v16xZszR37lw1NzersbFRS5Ys0dKlS7Vz50719vZq48aN0yo0EokoEokoGo0qHA5P670AAIC9Ug4nL774olatWpV43tzcLElqbGzUnj17tH79er3zzjvaunWruru7tWjRIh0+fPiiQbIAAADJpBxOVq5cOel0801NTWpqakq7KAAAULiyfrdOIesbjI16HgwUsQYPAABjEE6yIBgoUri8RJv3nxq1PVxeou3rFhJQAAAYwZlw4nmePM9TLBabfGfLhIoD2r5uoWLxDy+H9Q3GtHn/qVHbAABAhm8l9lMkElFHR4fa2tpyXUpaQsUBlYeCHz5KgrkuCQAAKzkTTgAAQGEgnAAAAKsQTgAAgFWcCSdMXw8AQGFwJpy4PiAWAABMjTO3EuerkROzMSkbAACEk5xJNjEbk7IBAEA4yZmxE7MxKRsAAB8gnOQQPSQAAFyMsyMAALCKM+GEW4kBACgMzoQTbiUGAKAwOBNOAABAYSCcAAAAqxBOAACAVQgnAADAKoQTAABgFSZhs8zItXYk1tsBABQeZ8KJ53nyPE+xWGzynR2UbK0difV2AACFx5lwEolEFIlEFI1GFQ6Hc11Oxo1da0divR0AQGFyJpwUAnpHAABgQCwAALAM4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCrOhBPP81RbW6v6+vpclwIAAHzkTDiJRCLq6OhQW1tbrksBAAA+YoZYB4xdDHAsFgcEAOQTwonFxlsMcCwWBwQA5BPCicWSLQY4FosDAgDyDeHEcvSGAAAKDWc+AABgFcIJAACwCuEEAABYhTEneWLk7cbcWgwAcBnhxHHJbjfm1mIAgMsIJ44be7sxtxYDAFznTDjxPE+e5ykWm3i21EJEDwkAIJ84c1ZjbR0AAAqDM+EEAAAUBsIJAACwCuEEAABYxZkBsUjNyHlPJOY+AQC4g3CSZ5LNeyIx9wkAwB2Ekzwzdt4TiblPAABuIZzkofF6R5jiHgDgAsJJAWCKewCASwgnBYAp7gEALiGcFAh6SAAAruCMBQAArEI4AQAAViGcAAAAqxBOAACAVRgQW8CY4h4AYCPCSQFiinsAgM2cCSee58nzPMViscl3xoQmmuL+Qv+QyuNBSfSkAAByw5lwEolEFIlEFI1GFQ6Hc12O88aGDmaRBQDYwplwAn8xiywAwBaEEyTQQwIAsAFnIwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAVuFuHUyIKe4BANlGOEFSE01xf/9nr1VJIJDYj7ACAMgkwgmSSjbF/WA8rvufeVl3721PbGMWWQBAphFOMK6xgaNcQWaRBQD4jnCClCTrIRk7LmUsLv0AAFJBOEHaxhuXMhaXfgAAqSCcIG3JxqWMxaUfAECqCCeYFnpDAACZxpkFAABYhZ4TZAWTuQEApopwAl9NNJkbg2QBAMkQTuCrZINmpzpIdmAoPmofelsAoDAQTuC78QLFyEs9Y4PHwFBcW379N53rG0xso7cFAAoD4QRZl+xSz9jgEYsbnesb1Pe/UKfykiC3JANAASGcIOvGXuqZKHiUlwRVHgpmu0QAQA5lvX+8q6tLK1euVG1trRYuXKj9+/dnuwRYIFQcUHnog+BRXvJB+OgbjKlv4P8ek0yJDwDIX1nvOSkuLtbOnTu1aNEidXd3a/Hixbrlllv0kY98JNulwBIT3dETDBTlqCoAQK5kPZzMmTNHc+bMkSTNnj1blZWVevfddwknBWy8afC5OwcAClPKR/4jR45o7dq1qq6uVlFRkQ4cOHDRPp7nad68eSorK9OyZct07NixpO91/PhxxWIx1dTUpFw48suoyzz/9yCYAEBhSvno39vbq7q6Onmel/Tn+/btU3Nzs1paWnTixAnV1dVp9erVevvtt0ft9+677+pLX/qSHn/88fQqBwAAeSnlyzpr1qzRmjVrxv35jh07tGnTJm3cuFGStGvXLh08eFC7d+/Wli1bJEn9/f269dZbtWXLFl1//fUTfl5/f7/6+/sTz6PRaKolAwAAh2S033xgYEDHjx9XQ0PDhx8QCKihoUFHjx6VJBljdMcdd+jmm2/Whg0bJn3Pbdu2KRwOJx5cAipso+7oGYhpYCie65IAABmW0QGxZ8+eVSwWU1VV1ajtVVVVevXVVyVJzz//vPbt26eFCxcmxqv87Gc/04IFC5K+57333qvm5ubE82g0SkApQKzRAwCFI+t369x4442Kx6f+bbe0tFSlpaU+VgQXTGeNHgCAWzIaTiorKxUMBtXT0zNqe09Pj2bPnp3Jj0IBoncEAApDRo/2oVBIixcvVmtra2JbPB5Xa2urli9fnsmPAgAAeSrlnpMLFy7o9OnTieednZ1qb2/XrFmzNHfuXDU3N6uxsVFLlizR0qVLtXPnTvX29ibu3kmX53nyPE+xGNOaY7SJVjcGALgn5XDy4osvatWqVYnnw4NVGxsbtWfPHq1fv17vvPOOtm7dqu7ubi1atEiHDx++aJBsqiKRiCKRiKLRqMLh8LTeC/lhKqsbAwDck3I4WblypYyZeABiU1OTmpqa0i4KmIqprm48MBQftS3d3pVMvQ8AYGJZv1sHyKTJwsHAUFxbfv03nesbTGybSu/K2CAyGI/r/mdeTvl9AACpI5wgr8XiRuf6BvX9L9SpvCQ4pd6VZEFE+iCM/L//XaSSQIDbmAHAR86EEwbEYjrKSz5YTHDYyEG04/WKDAeRYVO5jMOlHwCYPmfCCQNiMVUjg8fIf0sTzzQ7MoykEyrSvYQEABjNmXACTGai4BEMFElKPtPs8GunGyCmegkJADAxwgnyxlSDh9+9GGMvIQEAUkM4QV6x8fJJsktL6Vwy8qO3BwBsPL44E04YEAsbpTu+JZVxKMnGsqTzPgAwlq3HF2fCCQNiYZN0x7ekMw5l7FiWdN8HAMay9fjiTDgBbOL3+JaR3azDPTKMZQGQCS4cXwgnQJr86u4c75bk4R4ZAEiXK8cXwglgmWTdrLkenAbATWMHu/YNxpw4vhBOgBxLdvCQ7OtmBeAPv+6WmWiw6/+UFlsXSEYinAA5NNHBw49uVhtvGQQKmZ93yyTrhZXc+H/emXDCrcTIR9k8eNh6yyBQyKZzt8xU1/JysRfWmXDCrcTIZ9k4eNh6yyDgqkz2RKZ6DMj3tbycCScAMsPFb1GAbXLdE5nva3kRToAcGB70OnZWWQBusKUnMl+/bBBOgCxKNrOsjXMM5BKDduGSfA0HuUY4AbIo2cyy0znxjux5yeQJfKoD7TIt113lAOxAOAGyLBMn2PF6YDJxAs/lQDtbusoBevByi3ACOGhsD0wmT+B+DrSb6gGfrnJI9OClY6KV0l3iTDhhnhNgNL8PkGMDwmQHuslOHK4e8PkGnRv04I023kzSw6ayUrpLnAknzHMC5MZ4B72xJjtx2HjAn4wrgSpXPQx+suFWWVt68KYyk/RUV0p3hTPhBEBujHfQGymVE0e2DviZ6PFwIVDl+2RctgSEXJrqTNL58N97GOEEwKTSPeiNDAjZvP490TfN+z97rUoC4/8+ro2BsaGHAdlh899hphFOAPhivG/02bj+neyb5mA8rvufeVl3722f8LWu9joU0okrVfl42SvfEU6APJJskFyuDsLJAsJ49fg1Y+7IE3a5ghm9PAU32HjZK1c9ii4hnAB5YKKR+rnuBZjoG322Z8zl23L+S3ZXi02XvXLZo+gSwgmQB5INWh0+CF/oH1J5PGjlN7R0Z8xNNth1JBt/V/hvorFG/1NabEU4TaVHsZARToA8MfbglkqvRKYmbkrnfVI9KI93AhprOt9GWZjRTVO9qyWbxpufhDFCEyOcAHlqKr0SmZq4KZsTQI13AkpWU6onpHxamNGm8Ud+SjZ+w5YT/1TmJ0FyzoQTZogFUjfZyShTEzdlYwKosb0ZfpyAMnmZKZ3XZaK9bB5/lGm2j9+wsSfHFc6EE2aIBfyRqYOkXwdb2wfNpjuLrF93kUw0/siWqdeli0/Qk03Pnoyt4zeyEaTznTPhBEBhSrc3I1vSnUXWz8nTptI22VozaCrhbbqXP2w5+efTZcFcI5wAsJ4tQWSkTH07nmyBxVwFhuH9srEEQL5c/rA9SLuEcAIAKfDr23E2x4pMJTBketHDqYQ3W3pApoMgkhmEEwBIgV/fjnMxVmSiMODCoofTUSh3M7mKcAIAKfLrJJbOWJFU5mJJZ/6WfOjNGGmiHqrhRSGZ3yb3CCcA4Ih0B476OVDTtdl6k/VQJVsU0oaBrIU8GSDhBACyYDo9HsPSHTjq16WobMzW64exv3eyRSFzeZmHu34IJwDgu0zPFJrOpRY/TrR+ztabbTbVx10/hBMA8M3Ibvnp3CprW/c+k4z5r5CCSDKEEwDIsPG65VNdGde27n3b6kH+ciacsLYOAFdkqlvetu592+pB/nImnLC2DgCX2L5mUboyWY9tl6tgD2fCCQAgP3B5CJMhnAAAsorLQ5gM4QQAkJCtSy3pBpGRdXE5KH8RTgAA1l9qmWja+WzWyDiZ7CCcAACsv9SSrD4pezXaHt7yDeEEACDJvjuDxsplfbaHt3xDOAEAYAoIItlDSwMAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqzgTTjzPU21trerr63NdCgAA8JEz4SQSiaijo0NtbW25LgUAAPjImXACAAAKA+EEAABYxblViY35YLnqaDSa8ffuG4hpoO+CotGoBkPBjL8/AAC28+tcOHzeHj6PT6TITGUvi7z55puqqanJdRkAACANXV1duvzyyyfcx7lwEo/H9dZbb6miokJFRUUZfe9oNKqamhp1dXVp5syZGX1vfIh2zg7aOTto5+ygnbPHr7Y2xuj8+fOqrq5WIDDxqBLnLusEAoFJE9d0zZw5kz/+LKCds4N2zg7aOTto5+zxo63D4fCU9mNALAAAsArhBAAAWIVwMkJpaalaWlpUWlqa61LyGu2cHbRzdtDO2UE7Z48Nbe3cgFgAAJDf6DkBAABWIZwAAACrEE4AAIBVCCcAAMAqBRdOPM/TvHnzVFZWpmXLlunYsWMT7r9//35dc801Kisr04IFC3To0KEsVeq2VNr5iSee0IoVK3TppZfq0ksvVUNDw6T/XfCBVP+eh+3du1dFRUW69dZb/S0wT6Tazu+9954ikYjmzJmj0tJSzZ8/n2PHFKTazjt37tTVV1+t8vJy1dTU6O6779Z///vfLFXrpiNHjmjt2rWqrq5WUVGRDhw4MOlrnn32WX3yk59UaWmpPv7xj2vPnj2+1ylTQPbu3WtCoZDZvXu3efnll82mTZvMJZdcYnp6epLu//zzz5tgMGgeeeQR09HRYb7zne+YkpIS89JLL2W5crek2s6333678TzPnDx50rzyyivmjjvuMOFw2Lz55ptZrtwtqbbzsM7OTvOxj33MrFixwnz2s5/NTrEOS7Wd+/v7zZIlS8wtt9xinnvuOdPZ2WmeffZZ097enuXK3ZJqOz/55JOmtLTUPPnkk6azs9P87ne/M3PmzDF33313lit3y6FDh8x9991nnnrqKSPJPP300xPuf+bMGTNjxgzT3NxsOjo6zGOPPWaCwaA5fPiwr3UWVDhZunSpiUQiieexWMxUV1ebbdu2Jd3/tttuM5/+9KdHbVu2bJn56le/6mudrku1nccaGhoyFRUV5qc//alfJeaFdNp5aGjIXH/99eZHP/qRaWxsJJxMQart/MMf/tBceeWVZmBgIFsl5oVU2zkSiZibb7551Lbm5mZzww03+FpnPplKOPnmN79prr322lHb1q9fb1avXu1jZcYUzGWdgYEBHT9+XA0NDYltgUBADQ0NOnr0aNLXHD16dNT+krR69epx90d67TzW+++/r8HBQc2aNcuvMp2Xbjt/73vf02WXXaYvf/nL2SjTeem0829+8xstX75ckUhEVVVVuu666/Twww8rFotlq2znpNPO119/vY4fP5649HPmzBkdOnRIt9xyS1ZqLhS5Og86t/Bfus6ePatYLKaqqqpR26uqqvTqq68mfU13d3fS/bu7u32r03XptPNY3/rWt1RdXX3R/xD4UDrt/Nxzz+nHP/6x2tvbs1Bhfkinnc+cOaM//elP+uIXv6hDhw7p9OnTuuuuuzQ4OKiWlpZslO2cdNr59ttv19mzZ3XjjTfKGKOhoSF97Wtf07e//e1slFwwxjsPRqNR9fX1qby83JfPLZieE7hh+/bt2rt3r55++mmVlZXlupy8cf78eW3YsEFPPPGEKisrc11OXovH47rsssv0+OOPa/HixVq/fr3uu+8+7dq1K9el5ZVnn31WDz/8sH7wgx/oxIkTeuqpp3Tw4EE98MADuS4NGVAwPSeVlZUKBoPq6ekZtb2np0ezZ89O+prZs2entD/Sa+dhjz76qLZv364//vGPWrhwoZ9lOi/Vdv7nP/+p119/XWvXrk1si8fjkqTi4mK99tpruuqqq/wt2kHp/D3PmTNHJSUlCgaDiW2f+MQn1N3drYGBAYVCIV9rdlE67fzd735XGzZs0Fe+8hVJ0oIFC9Tb26s777xT9913nwIBvntnwnjnwZkzZ/rWayIVUM9JKBTS4sWL1dramtgWj8fV2tqq5cuXJ33N8uXLR+0vSX/4wx/G3R/ptbMkPfLII3rggQd0+PBhLVmyJBulOi3Vdr7mmmv00ksvqb29PfH4zGc+o1WrVqm9vV01NTXZLN8Z6fw933DDDTp9+nQi/EnS3//+d82ZM4dgMo502vn999+/KIAMB0LDknEZk7PzoK/DbS2zd+9eU1paavbs2WM6OjrMnXfeaS655BLT3d1tjDFmw4YNZsuWLYn9n3/+eVNcXGweffRR88orr5iWlhZuJZ6CVNt5+/btJhQKmV/96lfm3//+d+Jx/vz5XP0KTki1ncfibp2pSbWd//Wvf5mKigrT1NRkXnvtNfPb3/7WXHbZZebBBx/M1a/ghFTbuaWlxVRUVJhf/OIX5syZM+b3v/+9ueqqq8xtt92Wq1/BCefPnzcnT540J0+eNJLMjh07zMmTJ80bb7xhjDFmy5YtZsOGDYn9h28l3rx5s3nllVeM53ncSuyHxx57zMydO9eEQiGzdOlS88ILLyR+dtNNN5nGxsZR+//yl7808+fPN6FQyFx77bXm4MGDWa7YTam08xVXXGEkXfRoaWnJfuGOSfXveSTCydSl2s5//etfzbJly0xpaam58sorzUMPPWSGhoayXLV7UmnnwcFBc//995urrrrKlJWVmZqaGnPXXXeZ//znP9kv3CF//vOfkx5vh9u2sbHR3HTTTRe9ZtGiRSYUCpkrr7zS/OQnP/G9ziJj6P8CAAD2KJgxJwAAwA2EEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABgFcIJAACwCuEEAABY5f8D0zDjyA7QyCgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "b=np.linspace(0,1,101)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(Xbb_scores['Xbb_score'][:].reshape(-1), lw=0.8,bins=b,histtype='step', density=False, alpha=0.7)\n",
    "ax.semilogy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
